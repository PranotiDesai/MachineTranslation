{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English to Hindi Translation\n",
    "\n",
    "This project is aimed to create a machine translation for converting text from English to french using character based sequence to sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "We will load the parellel corpora text and and then do the below processing\n",
    "\n",
    "1. Read the data(We are only using the 10000 text from teh corpora as training on the entire corpora is taking too long one epoch is taking hours) \n",
    "2. Iterate through teh corpora line by line and extract source and its corrosponding target text.\n",
    "3. Parse characters of the each sentence for both source and target and store in it a list\n",
    "4. Create char to index mapping and index to char mapping for both source and target language\n",
    "    a. This mapping hels us to assign a unique identifier to each character\n",
    "    b . We can always look for the character given its unique identifiier using reverse mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "corpora = open('hin.txt', encoding='utf-8').read().split('\\n')\n",
    "src_txts = []\n",
    "trg_txts = []\n",
    "# dictionary to index each of the character in the source language \n",
    "# [key is index and value is source character]\n",
    "src_index_to_char_dict = {}\n",
    "# dictionary to get source character given its index - key is source character and value is index\n",
    "src_char_to_index_dict = {}\n",
    "# dictionary to index each of the character in the target language \n",
    "# [key is index and value is target character]\n",
    "trg_index_to_char_dict = {}\n",
    "\n",
    "# dictionary to get french character given its index \n",
    "# [key is target character and value is index]\n",
    "trg_char_to_index_dict = {}\n",
    "#ndex of the source language and target language\n",
    "src_index = 0\n",
    "trg_index = 1\n",
    "\n",
    "trg_tokens= set()\n",
    "sentence_count = len(corpora)\n",
    "\n",
    "# To store the maximum source and target text length\n",
    "max_src_len = 0\n",
    "max_trg_len = 0\n",
    "\n",
    "# iterate through each sentence and parse the text to extract source and target text and then \n",
    "# parse each  character to append to the list of characters. we also need to populate the index \n",
    "# to char and char to index dictionary for both source and target sequence\n",
    "\n",
    "for i in range(sentence_count):\n",
    "    textArray = corpora[i].split(\"\\t\")\n",
    "    src_txt = textArray[src_index]\n",
    "    trg_txt = \"\".join(['\\t',textArray[trg_index], '\\n'])\n",
    "    \n",
    "    for char in src_txt:\n",
    "        if char not in src_char_to_index_dict:\n",
    "            src_char_to_index_dict[char] = len(src_char_to_index_dict)\n",
    "            src_index_to_char_dict[len(src_index_to_char_dict)] = char\n",
    "    for char in trg_txt:\n",
    "        if char not in trg_char_to_index_dict:\n",
    "            trg_char_to_index_dict[char] = len(trg_char_to_index_dict)\n",
    "            trg_index_to_char_dict[len(trg_index_to_char_dict)] = char\n",
    "            \n",
    "    #find the maximum length text of the source as well as target language\n",
    "    if len(src_txt) > max_src_len:\n",
    "        max_src_len = len(src_txt)\n",
    "    if len(trg_txt) > max_trg_len:\n",
    "        max_trg_len = len(trg_txt)\n",
    "        \n",
    "    src_txts.append(src_txt)\n",
    "    trg_txts.append(trg_txt)\n",
    "\n",
    "src_char_tokens = sorted(list(src_char_to_index_dict.keys()))\n",
    "trg_char_tokens = sorted(list(trg_char_to_index_dict.keys()))\n",
    "\n",
    "src_index_to_char_dict = {}\n",
    "src_char_to_index_dict = {}\n",
    "trg_index_to_char_dict = {}\n",
    "trg_char_to_index_dict = {}\n",
    "\n",
    "for char in src_char_tokens:\n",
    "    if char not in src_char_to_index_dict:\n",
    "        src_char_to_index_dict[char] = len(src_char_to_index_dict)\n",
    "        src_index_to_char_dict[len(src_index_to_char_dict)] = char\n",
    "for char in trg_char_tokens:\n",
    "    if char not in trg_char_to_index_dict:\n",
    "        trg_char_to_index_dict[char] = len(trg_char_to_index_dict)\n",
    "        trg_index_to_char_dict[len(trg_index_to_char_dict)] = char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Mapping\n",
    "\n",
    "As we know that we need a numeric representation for teh text in order to run a machine learning algorith we need to encode the text data to some numeric reprsentation. We will use use teh below steps to achieve this conversion.\n",
    "\n",
    "1. We will create 2D matric for each sentence and having size equal to the number of characters in that language and length of the longest text. where each each row represents the one-hot-encoded representation of each character \n",
    "2. As we have a 2 matrix for each sentence soe overall we have a 3D matrix where each sentence has 2D matrix representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokens = np.zeros(shape=(sentence_count,max_src_len, len(src_char_to_index_dict)), dtype='float32')\n",
    "trg_tokens = np.zeros(shape=(sentence_count,max_trg_len, len(trg_char_to_index_dict)), dtype='float32')\n",
    "trg_seq = np.zeros((sentence_count, max_trg_len, len(trg_char_to_index_dict)),dtype='float32')\n",
    "\n",
    "for i in range(sentence_count):\n",
    "    src_txt = src_txts[i]\n",
    "    trg_txt = trg_txts[i]\n",
    "    for j in range(len(src_txt)):\n",
    "        char = src_txt[j]\n",
    "        src_tokens[i,j,src_char_to_index_dict[char]] = 1\n",
    "        \n",
    "    for j in range(len(trg_txt)):\n",
    "        char = trg_txt[j]\n",
    "        trg_tokens[i,j,trg_char_to_index_dict[char]] = 1\n",
    "        # Skip the first character to keep make the decorder use the data at next timestep\n",
    "        if j>0:\n",
    "            trg_seq[i,j-1,trg_char_to_index_dict[char]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the data into tran and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_Size =0.2\n",
    "idx = np.random.choice(src_tokens.shape[0],size=int(src_tokens.shape[0]*validation_Size),replace=False)\n",
    "\n",
    "val_src_tokens = src_tokens[idx]\n",
    "val_trg_tokens = trg_tokens[idx]\n",
    "val_tar_seq_tokens = trg_seq[idx]\n",
    "\n",
    "src_tokens = np.delete(src_tokens, idx, axis=0)\n",
    "trg_tokens = np.delete(trg_tokens, idx, axis=0)\n",
    "trg_seq = np.delete(trg_seq, idx, axis=0)\n",
    "\n",
    "val_src_txt = [src_txts[i] for i in idx]\n",
    "train_src_txt=[src_txts[i] for i in range(len(src_txts)) if i not in idx]\n",
    "\n",
    "val_trg_txt = [trg_txts[i] for i in idx]\n",
    "train_trg_txt=[trg_txts[i] for i in range(len(trg_txts)) if i not in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence to Sequence Model\n",
    "\n",
    "Now we will creat a sequence to sequence ENcoder Decorder LSTM network which works as below\n",
    "1. The first network is an LSTM encoder ehich takes the source langauge characters as input and returns the encoded output, hidden state and the cell state.\n",
    "2. The second network is a decoder network which takes the target character sequence and the encoder hidden and cell state as input and return the decoded output sequence which is passed to a fully connected layer to get the predicted sequence.\n",
    "3. We have 2 inference model one for encoder and one for decoder which is used to predict the target text for a given source text, the inference model is different then the training model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S2SModel:\n",
    "    def __init__(self, max_src_len, max_trg_len, src_vocab, src_rev_vocab, trg_vocab, trg_rev_vocab, encoder_cell, decoder_cell):\n",
    "        \"\"\"\n",
    "        Constructor for the S2SModel \n",
    "        :param src_vocb: longest text length in source language\n",
    "        :param src_rev_vocb: longest text length in target language\n",
    "        :param src_vocb: Vocabulary of the source language\n",
    "        :param src_rev_vocb: Reverse mapping of the source language Vocabulary\n",
    "        :param trg_vocb: Vocabulary of the source language\n",
    "        :param trg_rev_vocb: Reverse mapping of the source language Vocabulary\n",
    "        :param encoder_cell: Number of LSTM, cell to use in encoder\n",
    "        :param decoder_cell: Number of LSTM, cell to use in decoder\n",
    "        \"\"\"\n",
    "        self.max_src_len = max_src_len\n",
    "        self.max_trg_len = max_trg_len\n",
    "        self.src_vocab = src_vocab\n",
    "        self.src_rev_vocab = src_rev_vocab\n",
    "        self.trg_vocab = trg_vocab\n",
    "        self.trg_rev_vocab = trg_rev_vocab\n",
    "        \n",
    "        self.src_input_len = len(self.src_vocab)\n",
    "        self.trg_input_len = len(self.trg_vocab)\n",
    "        self.encoder_cell = encoder_cell\n",
    "        self.decoder_cell = decoder_cell\n",
    "        self.training_model = None\n",
    "        self.inference_model = None\n",
    "        self.history = None;\n",
    "        \n",
    "    def create(self, activation, optimizer, loss, metrices=None):\n",
    "        \"\"\"\n",
    "        This method creates the network by stacking the required layers \n",
    "        :param optimizer: Optimizer to use\n",
    "        :param loss: loss function to be yused as objective funcion\n",
    "        :param metrices: list of metrices to report while training\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        enc_input = Input(shape=(None,self.src_input_len))\n",
    "        enc_lstm = LSTM(self.encoder_cell,return_state = True)\n",
    "        enc_output, enc_hidden, enc_cell = enc_lstm(enc_input)\n",
    "        enc_states = [enc_hidden, enc_cell]\n",
    "        dec_input = Input(shape=(None,self.trg_input_len))\n",
    "        # set return_sequences to True so that we obtain the output at every timestep\n",
    "        dec_lstm = LSTM(self.decoder_cell, return_sequences=True, return_state = True)\n",
    "        dec_output,_ , _ = dec_lstm(dec_input,enc_states)\n",
    "        fc_layer = Dense(self.trg_input_len, activation=activation)\n",
    "        fc_output = fc_layer(dec_output)\n",
    "        self.training_model = Model (inputs=[enc_input,dec_input],outputs=fc_output)\n",
    "        if metrices is None:\n",
    "            self.training_model.compile(optimizer=optimizer, loss=loss)\n",
    "        else:\n",
    "            self.training_model.compile(optimizer=optimizer, loss=loss, metrices=metrices)\n",
    "            \n",
    "        #encoder inference model\n",
    "        enc_inf_model = Model(enc_input,enc_states)\n",
    "        \n",
    "        #decoder inference model\n",
    "        dec_input_states = [Input(shape=(self.decoder_cell,)),Input(shape=(self.decoder_cell,))]\n",
    "        dec_output, dec_hidden, dec_cell = dec_lstm(dec_input, initial_state=dec_input_states)\n",
    "        fc_output = fc_layer(dec_output)\n",
    "        dec_inf_model = Model(inputs=[dec_input]+dec_input_states,  outputs=[fc_output]+[dec_hidden, dec_cell])\n",
    "        self.inference_model={\"encoder\":enc_inf_model,\"decoder\":dec_inf_model}\n",
    "        \n",
    "    def train(self, enc_input,dec_input, target_sequence, epochs, batch_size=64, validation_data=None):\n",
    "        \"\"\"\n",
    "        This method is used to train the training_model\n",
    "        :param enc_input: Input for th encoder\n",
    "        :param dec_input: Input for th decoder\n",
    "        :param target_sequence: target sequence to predict\n",
    "        :param epochs: Number of epochs to train\n",
    "        :param batch_size: size of each batch for training\n",
    "        :param validation_data: validatin data for the evlauating model\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.history = self.training_model.fit([enc_input,dec_input],target_sequence, epochs=epochs, batch_size=batch_size,\n",
    "                                      validation_data=validation_data, validation_split=0.2)\n",
    "    \n",
    "    \n",
    "    def predict(self, src_seq):\n",
    "        \"\"\"\n",
    "        This function predicts teh target sequence for a given source sequence\n",
    "        :param \n",
    "        :return\n",
    "        \"\"\"\n",
    "        decoder_input_states = self.inference_model['encoder'].predict(src_seq)\n",
    "        #Set the start of the sequence\n",
    "        trg_seq = np.zeros((1, 1, self.trg_input_len))\n",
    "        trg_seq[0, 0, 0] = 1\n",
    "        predicted_text = ''\n",
    "        \n",
    "        while True:  \n",
    "            dec_output, dec_hidden, dec_cell = self.inference_model['decoder'].predict(x=[trg_seq]+decoder_input_states)\n",
    "            predicted_sequence = np.argmax(dec_output[0,-1,:]) \n",
    "            predicted_text+=self.trg_rev_vocab[predicted_sequence]\n",
    "            #Check teh end of sequence marker represented by a new line\n",
    "            if len(predicted_text) > self.max_trg_len or predicted_sequence == self.trg_vocab[\"\\n\"]:\n",
    "                break\n",
    "            else:\n",
    "                #Update the target sequence\n",
    "                trg_seq = np.zeros((1, 1, self.trg_input_len))\n",
    "                trg_seq[0, 0, predicted_sequence] = 1\n",
    "                decoder_input_states = [dec_hidden, dec_cell]\n",
    "        return predicted_text\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        \"\"\"\n",
    "        This function plots the training and validation loss for visualization\n",
    "        :param \n",
    "        :return\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(5,3))\n",
    "        plt.plot(S2S.history.history['loss'])\n",
    "        plt.plot(S2S.history.history['val_loss'])\n",
    "        plt.legend([\"Training Loss\", \"Validation Loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1834 samples, validate on 459 samples\n",
      "Epoch 1/50\n",
      "1834/1834 [==============================] - 18s 10ms/step - loss: 0.8243 - val_loss: 1.2968\n",
      "Epoch 2/50\n",
      "1834/1834 [==============================] - 21s 12ms/step - loss: 0.7623 - val_loss: 1.2621\n",
      "Epoch 3/50\n",
      "1834/1834 [==============================] - 19s 10ms/step - loss: 0.7349 - val_loss: 1.2095\n",
      "Epoch 4/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.6874 - val_loss: 1.1313\n",
      "Epoch 5/50\n",
      "1834/1834 [==============================] - 16s 8ms/step - loss: 0.6409 - val_loss: 1.0771\n",
      "Epoch 6/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.6036 - val_loss: 1.0303\n",
      "Epoch 7/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.5748 - val_loss: 0.9875\n",
      "Epoch 8/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.5490 - val_loss: 0.9524\n",
      "Epoch 9/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.5295 - val_loss: 0.9225\n",
      "Epoch 10/50\n",
      "1834/1834 [==============================] - 16s 8ms/step - loss: 0.5128 - val_loss: 0.9057\n",
      "Epoch 11/50\n",
      "1834/1834 [==============================] - 16s 8ms/step - loss: 0.4996 - val_loss: 0.8844\n",
      "Epoch 12/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.4879 - val_loss: 0.8791\n",
      "Epoch 13/50\n",
      "1834/1834 [==============================] - 15s 8ms/step - loss: 0.4779 - val_loss: 0.8650\n",
      "Epoch 14/50\n",
      "1834/1834 [==============================] - 15s 8ms/step - loss: 0.4700 - val_loss: 0.8634\n",
      "Epoch 15/50\n",
      "1834/1834 [==============================] - 15s 8ms/step - loss: 0.4678 - val_loss: 0.8462\n",
      "Epoch 16/50\n",
      "1834/1834 [==============================] - 15s 8ms/step - loss: 0.4549 - val_loss: 0.8392\n",
      "Epoch 17/50\n",
      "1834/1834 [==============================] - 17s 9ms/step - loss: 0.4495 - val_loss: 0.8335\n",
      "Epoch 18/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.4418 - val_loss: 0.8140\n",
      "Epoch 19/50\n",
      "1834/1834 [==============================] - 15s 8ms/step - loss: 0.4356 - val_loss: 0.8204\n",
      "Epoch 20/50\n",
      "1834/1834 [==============================] - 15s 8ms/step - loss: 0.4299 - val_loss: 0.8182\n",
      "Epoch 21/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.4274 - val_loss: 0.8042\n",
      "Epoch 22/50\n",
      "1834/1834 [==============================] - 17s 9ms/step - loss: 0.4185 - val_loss: 0.7965\n",
      "Epoch 23/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.4138 - val_loss: 0.7904\n",
      "Epoch 24/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.4084 - val_loss: 0.7916\n",
      "Epoch 25/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.4033 - val_loss: 0.7880\n",
      "Epoch 26/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.3979 - val_loss: 0.7895\n",
      "Epoch 27/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.3933 - val_loss: 0.7792\n",
      "Epoch 28/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.3884 - val_loss: 0.7794\n",
      "Epoch 29/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.3831 - val_loss: 0.7852\n",
      "Epoch 30/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.3792 - val_loss: 0.7785\n",
      "Epoch 31/50\n",
      "1834/1834 [==============================] - 15s 8ms/step - loss: 0.3737 - val_loss: 0.7724\n",
      "Epoch 32/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.3702 - val_loss: 0.7730\n",
      "Epoch 33/50\n",
      "1834/1834 [==============================] - 15s 8ms/step - loss: 0.3645 - val_loss: 0.7696\n",
      "Epoch 34/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.3600 - val_loss: 0.7647\n",
      "Epoch 35/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.3558 - val_loss: 0.7739\n",
      "Epoch 36/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.3507 - val_loss: 0.7784\n",
      "Epoch 37/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.3463 - val_loss: 0.7724\n",
      "Epoch 38/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.3416 - val_loss: 0.7718\n",
      "Epoch 39/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.3363 - val_loss: 0.7685\n",
      "Epoch 40/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.3316 - val_loss: 0.7771\n",
      "Epoch 41/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.3498 - val_loss: 0.7872\n",
      "Epoch 42/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.3461 - val_loss: 0.7820\n",
      "Epoch 43/50\n",
      "1834/1834 [==============================] - 16s 8ms/step - loss: 0.3323 - val_loss: 0.7803\n",
      "Epoch 44/50\n",
      "1834/1834 [==============================] - 15s 8ms/step - loss: 0.3239 - val_loss: 0.7819\n",
      "Epoch 45/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.3170 - val_loss: 0.7824\n",
      "Epoch 46/50\n",
      "1834/1834 [==============================] - 15s 8ms/step - loss: 0.3121 - val_loss: 0.7849\n",
      "Epoch 47/50\n",
      "1834/1834 [==============================] - 15s 8ms/step - loss: 0.3069 - val_loss: 0.7863\n",
      "Epoch 48/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.3020 - val_loss: 0.8037\n",
      "Epoch 49/50\n",
      "1834/1834 [==============================] - 16s 8ms/step - loss: 0.2968 - val_loss: 0.8023\n",
      "Epoch 50/50\n",
      "1834/1834 [==============================] - 16s 9ms/step - loss: 0.2918 - val_loss: 0.8042\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enc_input_len = len(src_char_to_index_dict)\n",
    "dec_input_len = len(trg_char_to_index_dict)\n",
    "S2S = S2SModel(max_src_len, max_trg_len, src_char_to_index_dict,src_index_to_char_dict, \n",
    "               trg_char_to_index_dict, trg_index_to_char_dict, 256,256)\n",
    "S2S.create(\"softmax\",\"rmsprop\", \"categorical_crossentropy\")\n",
    "S2S.train(src_tokens, trg_tokens, trg_seq, epochs=50, batch_size=64)\n",
    "S2S.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_bleu_core(src_tokens,src_text, target_text, sample_count, weights):\n",
    "    \"\"\"\n",
    "    It computes teh average bleu score on the given data by takeing some random sample\n",
    "    :param src_tokens: source text tockens\n",
    "    :param src_text: source text\n",
    "    :param target_text: Actual target text\n",
    "    :param sample_count: Random Sample to take\n",
    "    :param weights: weights for n-grams\n",
    "    :return\n",
    "    \"\"\"\n",
    "    index = np.random.choice(source_tokens.shape[0], size=sample_count, replace=False)\n",
    "    bleu = 0\n",
    "    for i in index:\n",
    "        source = src_tokens[index]\n",
    "        predicted_text = S2S.predict(source)\n",
    "        target_text = trg_txts[i].strip()\n",
    "        bleu+=nltk.translate.bleu_score.sentence_bleu([predicted_text],target_text,weights=weights)\n",
    "        #Print one Candidate Translation\n",
    "        if i==index[0]:\n",
    "            print('Target Sentence:', target_text)\n",
    "            print('Decoded Sentence:', predicted_text)\n",
    "    return bleu/sample_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Sentence: तुम्हें याद है उसने क्या कहा था?\n",
      "Decoded Sentence: तुम काई करता है क्या?\n",
      "\n",
      "The Average bleu score on 10 random text in Training data:0.460\n",
      "Target Sentence: मुझे भूख लगी है।\n",
      "Decoded Sentence: तुम काई करता है क्या?\n",
      "\n",
      "The Average bleu score on 10 random text on Validation data:0.312\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "weights = [1.0, 0, 0, 0]\n",
    "sample_count = 10 #Number of sentences to consider\n",
    "source_tokens = src_tokens\n",
    "source_texts = train_src_txt\n",
    "target_texts = trg_txts\n",
    "bleu=compute_avg_bleu_core(source_tokens, source_texts, target_texts,sample_count, weights)\n",
    "print(\"The Average bleu score on 10 random text in Training data:%.3f\"%bleu)\n",
    "\n",
    "source_tokens = val_src_tokens\n",
    "source_texts = val_src_txt\n",
    "target_texts = val_trg_tokens\n",
    "bleu=compute_avg_bleu_core(source_tokens, source_texts, target_texts,sample_count, weights)\n",
    "print(\"The Average bleu score on 10 random text on Validation data:%.3f\"%bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Sentence: अपना मूँह खोलो!\n",
      "Decoded Sentence: मैं तुम्हारे पास आऊँगा।\n",
      "\n",
      "The Average bleu score on 10 random text in Training data:0.164\n",
      "Target Sentence: वह वहाँ गया क्या?\n",
      "Decoded Sentence: तुम काई करता है क्या?\n",
      "\n",
      "The Average bleu score on 10 random text on Validation data:0.243\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(11)\n",
    "weights = [0.5, 0.5, 0, 0]\n",
    "sample_count = 10 #Number of sentences to consider\n",
    "source_tokens = src_tokens\n",
    "source_texts = train_src_txt\n",
    "target_texts = trg_txts\n",
    "bleu=compute_avg_bleu_core(source_tokens, source_texts, target_texts,sample_count, weights)\n",
    "print(\"The Average bleu score on 10 random text in Training data:%.3f\"%bleu)\n",
    "\n",
    "source_tokens = val_src_tokens\n",
    "source_texts = val_src_txt\n",
    "target_texts = val_trg_tokens\n",
    "bleu=compute_avg_bleu_core(source_tokens, source_texts, target_texts,sample_count, weights)\n",
    "print(\"The Average bleu score on 10 random text on Validation data:%.3f\"%bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Sentence: पत्थर मत फेंको।\n",
      "Decoded Sentence: मैं तुम्हें यह करता हूँ।\n",
      "\n",
      "The Average bleu score on 10 random text in Training data:0.117\n",
      "Target Sentence: मेरी है, उसकी नहीं।\n",
      "Decoded Sentence: मैं तुम्हें यह करता हूँ।\n",
      "\n",
      "The Average bleu score on 10 random text on Validation data:0.141\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(21)\n",
    "weights = [0.33, 0.33, 0.33, 0]\n",
    "sample_count = 10 #Number of sentences to consider\n",
    "source_tokens = src_tokens\n",
    "source_texts = train_src_txt\n",
    "target_texts = trg_txts\n",
    "bleu=compute_avg_bleu_core(source_tokens, source_texts, target_texts,sample_count, weights)\n",
    "print(\"The Average bleu score on 10 random text in Training data:%.3f\"%bleu)\n",
    "\n",
    "source_tokens = val_src_tokens\n",
    "source_texts = val_src_txt\n",
    "target_texts = val_trg_tokens\n",
    "bleu=compute_avg_bleu_core(source_tokens, source_texts, target_texts,sample_count, weights)\n",
    "print(\"The Average bleu score on 10 random text on Validation data:%.3f\"%bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The 1-gram bleu score is 0.47 for the training data and 0.31 for the test data, 2-gram bleu core is 0.16 for training and 0.24 for testing and 3-gram bleu core is 0.11 for training and 0.14 for testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2S.training_model.save(\"training_model_hin.h5\")\n",
    "S2S.inference_model['encoder'].save(\"enc_inference_hin.h5\")\n",
    "S2S.inference_model['decoder'].save(\"dec_inference_hin.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-cv3-dlib-gpu",
   "language": "python",
   "name": "tf-cv3-dlib-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
