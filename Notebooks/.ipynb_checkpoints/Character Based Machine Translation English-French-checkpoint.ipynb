{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English to Hindi Translation\n",
    "\n",
    "This project is aimed to create a machine translation for converting text from English to french using character based sequence to sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "We will load the parellel corpora text and and then do the below processing\n",
    "\n",
    "1. Read the data(We are only using the 10000 text from teh corpora as training on the entire corpora is taking too long one epoch is taking hours) \n",
    "2. Iterate through teh corpora line by line and extract source and its corrosponding target text.\n",
    "3. Parse characters of the each sentence for both source and target and store in it a list\n",
    "4. Create char to index mapping and index to char mapping for both source and target language\n",
    "    a. This mapping hels us to assign a unique identifier to each character\n",
    "    b . We can always look for the character given its unique identifiier using reverse mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "corpora = open('fra.txt', encoding='utf-8').read().split('\\n')\n",
    "src_txts = []\n",
    "trg_txts = []\n",
    "# dictionary to index each of the character in the source language \n",
    "# [key is index and value is source character]\n",
    "src_index_to_char_dict = {}\n",
    "# dictionary to get source character given its index - key is source character and value is index\n",
    "src_char_to_index_dict = {}\n",
    "# dictionary to index each of the character in the target language \n",
    "# [key is index and value is target character]\n",
    "trg_index_to_char_dict = {}\n",
    "\n",
    "# dictionary to get french character given its index \n",
    "# [key is target character and value is index]\n",
    "trg_char_to_index_dict = {}\n",
    "#ndex of the source language and target language\n",
    "src_index = 0\n",
    "trg_index = 1\n",
    "\n",
    "trg_tokens= set()\n",
    "sentence_count = 10000\n",
    "\n",
    "# To store the maximum source and target text length\n",
    "max_src_len = 0\n",
    "max_trg_len = 0\n",
    "\n",
    "# iterate through each sentence and parse the text to extract source and target text and then \n",
    "# parse each  character to append to the list of characters. we also need to populate the index \n",
    "# to char and char to index dictionary for both source and target sequence\n",
    "\n",
    "for i in  range(sentence_count):\n",
    "    textArray = corpora[i].split(\"\\t\")\n",
    "    #unicodedata.normalize('NFD', eng).encode('ascii', 'ignore').decode('UTF-8')\n",
    "    src_txt = textArray[src_index]\n",
    "    trg_txt = \"\".join(['\\t',textArray[trg_index], '\\n'])\n",
    "    \n",
    "    for char in src_txt:\n",
    "        if char not in src_char_to_index_dict:\n",
    "            src_char_to_index_dict[char] = len(src_char_to_index_dict)\n",
    "            src_index_to_char_dict[len(src_index_to_char_dict)] = char\n",
    "    for char in trg_txt:\n",
    "        if char not in trg_char_to_index_dict:\n",
    "            trg_char_to_index_dict[char] = len(trg_char_to_index_dict)\n",
    "            trg_index_to_char_dict[len(trg_index_to_char_dict)] = char\n",
    "            \n",
    "    #find the maximum length text of the source as well as target language\n",
    "    if len(src_txt) > max_src_len:\n",
    "        max_src_len = len(src_txt)\n",
    "    if len(trg_txt) > max_trg_len:\n",
    "        max_trg_len = len(trg_txt)\n",
    "        \n",
    "    src_txts.append(src_txt)\n",
    "    trg_txts.append(trg_txt)\n",
    "\n",
    "src_char_tokens = sorted(list(src_char_to_index_dict.keys()))\n",
    "trg_char_tokens = sorted(list(trg_char_to_index_dict.keys()))\n",
    "\n",
    "src_index_to_char_dict = {}\n",
    "src_char_to_index_dict = {}\n",
    "trg_index_to_char_dict = {}\n",
    "trg_char_to_index_dict = {}\n",
    "\n",
    "for char in src_char_tokens:\n",
    "    if char not in src_char_to_index_dict:\n",
    "        src_char_to_index_dict[char] = len(src_char_to_index_dict)\n",
    "        src_index_to_char_dict[len(src_index_to_char_dict)] = char\n",
    "for char in trg_char_tokens:\n",
    "    if char not in trg_char_to_index_dict:\n",
    "        trg_char_to_index_dict[char] = len(trg_char_to_index_dict)\n",
    "        trg_index_to_char_dict[len(trg_index_to_char_dict)] = char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Mapping\n",
    "\n",
    "As we know that we need a numeric representation for teh text in order to run a machine learning algorith we need to encode the text data to some numeric reprsentation. We will use use teh below steps to achieve this conversion.\n",
    "\n",
    "1. We will create 2D matric for each sentence and having size equal to the number of characters in that language and length of the longest text. where each each row represents the one-hot-encoded representation of each character \n",
    "2. As we have a 2 matrix for each sentence soe overall we have a 3D matrix where each sentence has 2D matrix representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokens = np.zeros(shape=(sentence_count,max_src_len, len(src_char_to_index_dict)), dtype='float32')\n",
    "trg_tokens = np.zeros(shape=(sentence_count,max_trg_len, len(trg_char_to_index_dict)), dtype='float32')\n",
    "trg_seq = np.zeros((sentence_count, max_trg_len, len(trg_char_to_index_dict)),dtype='float32')\n",
    "\n",
    "for i in range(sentence_count):\n",
    "    src_txt = src_txts[i]\n",
    "    trg_txt = trg_txts[i]\n",
    "    for j in range(len(src_txt)):\n",
    "        char = src_txt[j]\n",
    "        src_tokens[i,j,src_char_to_index_dict[char]] = 1\n",
    "        \n",
    "    for j in range(len(trg_txt)):\n",
    "        char = trg_txt[j]\n",
    "        trg_tokens[i,j,trg_char_to_index_dict[char]] = 1\n",
    "        # Skip the first character to keep make the decorder use the data at next timestep\n",
    "        if j>0:\n",
    "            trg_seq[i,j-1,trg_char_to_index_dict[char]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the data into tran and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_Size =0.2\n",
    "idx = np.random.choice(src_tokens.shape[0],size=int(src_tokens.shape[0]*validation_Size),replace=False)\n",
    "\n",
    "val_src_tokens = src_tokens[idx]\n",
    "val_trg_tokens = trg_tokens[idx]\n",
    "val_tar_seq_tokens = trg_seq[idx]\n",
    "\n",
    "src_tokens = np.delete(src_tokens, idx, axis=0)\n",
    "trg_tokens = np.delete(trg_tokens, idx, axis=0)\n",
    "trg_seq = np.delete(trg_seq, idx, axis=0)\n",
    "\n",
    "val_src_txt = [src_txts[i] for i in idx]\n",
    "train_src_txt=[src_txts[i] for i in range(len(src_txts)) if i not in idx]\n",
    "\n",
    "val_trg_txt = [trg_txts[i] for i in idx]\n",
    "train_trg_txt=[trg_txts[i] for i in range(len(trg_txts)) if i not in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence to Sequence Model\n",
    "\n",
    "Now we will creat a sequence to sequence ENcoder Decorder LSTM network which works as below\n",
    "1. The first network is an LSTM encoder ehich takes the source langauge characters as input and returns the encoded output, hidden state and the cell state.\n",
    "2. The second network is a decoder network which takes the target character sequence and the encoder hidden and cell state as input and return the decoded output sequence which is passed to a fully connected layer to get the predicted sequence.\n",
    "3. We have 2 inference model one for encoder and one for decoder which is used to predict the target text for a given source text, the inference model is different then the training model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S2SModel:\n",
    "    def __init__(self, max_src_len, max_trg_len, src_vocab, src_rev_vocab, trg_vocab, trg_rev_vocab, encoder_cell, decoder_cell):\n",
    "        \"\"\"\n",
    "        Constructor for the S2SModel \n",
    "        :param src_vocb: longest text length in source language\n",
    "        :param src_rev_vocb: longest text length in target language\n",
    "        :param src_vocb: Vocabulary of the source language\n",
    "        :param src_rev_vocb: Reverse mapping of the source language Vocabulary\n",
    "        :param trg_vocb: Vocabulary of the source language\n",
    "        :param trg_rev_vocb: Reverse mapping of the source language Vocabulary\n",
    "        :param encoder_cell: Number of LSTM, cell to use in encoder\n",
    "        :param decoder_cell: Number of LSTM, cell to use in decoder\n",
    "        \"\"\"\n",
    "        self.max_src_len = max_src_len\n",
    "        self.max_trg_len = max_trg_len\n",
    "        self.src_vocab = src_vocab\n",
    "        self.src_rev_vocab = src_rev_vocab\n",
    "        self.trg_vocab = trg_vocab\n",
    "        self.trg_rev_vocab = trg_rev_vocab\n",
    "        \n",
    "        self.src_input_len = len(self.src_vocab)\n",
    "        self.trg_input_len = len(self.trg_vocab)\n",
    "        self.encoder_cell = encoder_cell\n",
    "        self.decoder_cell = decoder_cell\n",
    "        self.training_model = None\n",
    "        self.inference_model = None\n",
    "        self.history = None;\n",
    "        \n",
    "    def create(self, activation, optimizer, loss, metrices=None):\n",
    "        \"\"\"\n",
    "        This method creates the network by stacking the required layers \n",
    "        :param optimizer: Optimizer to use\n",
    "        :param loss: loss function to be yused as objective funcion\n",
    "        :param metrices: list of metrices to report while training\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        enc_input = Input(shape=(None,self.src_input_len))\n",
    "        enc_lstm = LSTM(self.encoder_cell,return_state = True)\n",
    "        enc_output, enc_hidden, enc_cell = enc_lstm(enc_input)\n",
    "        enc_states = [enc_hidden, enc_cell]\n",
    "        dec_input = Input(shape=(None,self.trg_input_len))\n",
    "        # set return_sequences to True so that we obtain the output at every timestep\n",
    "        dec_lstm = LSTM(self.decoder_cell, return_sequences=True, return_state = True)\n",
    "        dec_output,_ , _ = dec_lstm(dec_input,enc_states)\n",
    "        fc_layer = Dense(self.trg_input_len, activation=activation)\n",
    "        fc_output = fc_layer(dec_output)\n",
    "        self.training_model = Model (inputs=[enc_input,dec_input],outputs=fc_output)\n",
    "        if metrices is None:\n",
    "            self.training_model.compile(optimizer=optimizer, loss=loss)\n",
    "        else:\n",
    "            self.training_model.compile(optimizer=optimizer, loss=loss, metrices=metrices)\n",
    "            \n",
    "        #encoder inference model\n",
    "        enc_inf_model = Model(enc_input,enc_states)\n",
    "        \n",
    "        #decoder inference model\n",
    "        dec_input_states = [Input(shape=(self.decoder_cell,)),Input(shape=(self.decoder_cell,))]\n",
    "        dec_output, dec_hidden, dec_cell = dec_lstm(dec_input, initial_state=dec_input_states)\n",
    "        fc_output = fc_layer(dec_output)\n",
    "        dec_inf_model = Model(inputs=[dec_input]+dec_input_states,  outputs=[fc_output]+[dec_hidden, dec_cell])\n",
    "        self.inference_model={\"encoder\":enc_inf_model,\"decoder\":dec_inf_model}\n",
    "        \n",
    "    def train(self, enc_input,dec_input, target_sequence, epochs, batch_size=64, validation_data=None):\n",
    "        \"\"\"\n",
    "        This method is used to train the training_model\n",
    "        :param enc_input: Input for th encoder\n",
    "        :param dec_input: Input for th decoder\n",
    "        :param target_sequence: target sequence to predict\n",
    "        :param epochs: Number of epochs to train\n",
    "        :param batch_size: size of each batch for training\n",
    "        :param validation_data: validatin data for the evlauating model\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.history = self.training_model.fit([enc_input,dec_input],target_sequence, epochs=epochs, batch_size=batch_size,\n",
    "                                      validation_data=validation_data, validation_split=0.2)\n",
    "    \n",
    "    \n",
    "    def predict(self, src_seq):\n",
    "        \"\"\"\n",
    "        This function predicts teh target sequence for a given source sequence\n",
    "        :param \n",
    "        :return\n",
    "        \"\"\"\n",
    "        decoder_input_states = self.inference_model['encoder'].predict(src_seq)\n",
    "        #Set the start of the sequence\n",
    "        trg_seq = np.zeros((1, 1, self.trg_input_len))\n",
    "        trg_seq[0, 0, 0] = 1\n",
    "        predicted_text = ''\n",
    "        \n",
    "        while True:  \n",
    "            dec_output, dec_hidden, dec_cell = self.inference_model['decoder'].predict(x=[trg_seq]+decoder_input_states)\n",
    "            predicted_sequence = np.argmax(dec_output[0,-1,:]) \n",
    "            predicted_text+=self.trg_rev_vocab[predicted_sequence]\n",
    "            #Check teh end of sequence marker represented by a new line\n",
    "            if len(predicted_text) > self.max_trg_len or predicted_sequence == self.trg_vocab[\"\\n\"]:\n",
    "                break\n",
    "            else:\n",
    "                #Update the target sequence\n",
    "                trg_seq = np.zeros((1, 1, self.trg_input_len))\n",
    "                trg_seq[0, 0, predicted_sequence] = 1\n",
    "                decoder_input_states = [dec_hidden, dec_cell]\n",
    "        return predicted_text\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        \"\"\"\n",
    "        This function plots the training and validation loss for visualization\n",
    "        :param \n",
    "        :return\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(5,3))\n",
    "        plt.plot(S2S.history.history['loss'])\n",
    "        plt.plot(S2S.history.history['val_loss'])\n",
    "        plt.legend([\"Training Loss\", \"Validation Loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 0.9730 - val_loss: 1.0737\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.8689 - val_loss: 0.9572\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.7647 - val_loss: 0.8602\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.6812 - val_loss: 0.7745\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.6253 - val_loss: 0.7369\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.5868 - val_loss: 0.6920\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.5570 - val_loss: 0.6687\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.5308 - val_loss: 0.6392\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.5083 - val_loss: 0.6289\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4889 - val_loss: 0.6147\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4732 - val_loss: 0.5995\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4576 - val_loss: 0.5840\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4432 - val_loss: 0.5852\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4307 - val_loss: 0.5594\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4183 - val_loss: 0.5519\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4066 - val_loss: 0.5444\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.3962 - val_loss: 0.5351\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.3858 - val_loss: 0.5350\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.3758 - val_loss: 0.5347\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.3666 - val_loss: 0.5190\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.3584 - val_loss: 0.5236\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.3497 - val_loss: 0.5123\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.3416 - val_loss: 0.5066\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.3339 - val_loss: 0.5039\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.3260 - val_loss: 0.5045\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.3185 - val_loss: 0.5020\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.3114 - val_loss: 0.4926\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.3037 - val_loss: 0.5000\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2972 - val_loss: 0.5018\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2908 - val_loss: 0.4961\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2841 - val_loss: 0.4900\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2780 - val_loss: 0.4940\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2719 - val_loss: 0.4972\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2658 - val_loss: 0.4926\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2602 - val_loss: 0.4961\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2549 - val_loss: 0.4999\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2489 - val_loss: 0.4983\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2436 - val_loss: 0.4997\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2386 - val_loss: 0.5069\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2333 - val_loss: 0.4998\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2285 - val_loss: 0.5041\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2239 - val_loss: 0.5105\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2190 - val_loss: 0.5104\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2143 - val_loss: 0.5135\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2102 - val_loss: 0.5240\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2055 - val_loss: 0.5132\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.2016 - val_loss: 0.5188\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.1974 - val_loss: 0.5294\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.1937 - val_loss: 0.5245\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.1896 - val_loss: 0.5298\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enc_input_len = len(src_char_to_index_dict)\n",
    "dec_input_len = len(trg_char_to_index_dict)\n",
    "S2S = S2SModel(max_src_len, max_trg_len, src_char_to_index_dict,src_index_to_char_dict, \n",
    "               trg_char_to_index_dict, trg_index_to_char_dict, 256,256)\n",
    "S2S.create(\"softmax\",\"rmsprop\", \"categorical_crossentropy\")\n",
    "S2S.train(src_tokens, trg_tokens, trg_seq, epochs=50, batch_size=128)\n",
    "S2S.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_bleu_core(src_tokens,src_text, target_text, sample_count, weights):\n",
    "    \"\"\"\n",
    "    It computes teh average bleu score on the given data by takeing some random sample\n",
    "    :param src_tokens: source text tockens\n",
    "    :param src_text: source text\n",
    "    :param target_text: Actual target text\n",
    "    :param sample_count: Random Sample to take\n",
    "    :param weights: weights for n-grams\n",
    "    :return\n",
    "    \"\"\"\n",
    "    index = np.random.choice(source_tokens.shape[0], size=sample_count, replace=False)\n",
    "    bleu = 0\n",
    "    for i in index:\n",
    "        source = src_tokens[index]\n",
    "        predicted_text = S2S.predict(source)\n",
    "        target_text = trg_txts[i].strip()\n",
    "        bleu+=nltk.translate.bleu_score.sentence_bleu([predicted_text],target_text,weights=weights)\n",
    "        #Print one Candidate Translation\n",
    "        if i==index[0]:\n",
    "            print('Target Sentence:', target_text)\n",
    "            print('Decoded Sentence:', predicted_text)\n",
    "    return bleu/sample_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Sentence: Je ne suis pas nerveuse.\n",
      "Decoded Sentence: Je ne suis pas sourd.\n",
      "\n",
      "The Average bleu score on 10 random text in Training data:0.481\n",
      "\n",
      "Target Sentence: Je suis seul.\n",
      "Decoded Sentence: Êtes-vous sourd ?\n",
      "\n",
      "The Average bleu score on 10 random text on Validation data:0.327\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "weights = [1.0, 0, 0, 0]\n",
    "sample_count = 10 #Number of sentences to consider\n",
    "source_tokens = src_tokens\n",
    "source_texts = train_src_txt\n",
    "target_texts = trg_txts\n",
    "bleu=compute_avg_bleu_core(source_tokens, source_texts, target_texts,sample_count, weights)\n",
    "print(\"The Average bleu score on 10 random text in Training data:%.3f\\n\"%bleu)\n",
    "\n",
    "source_tokens = val_src_tokens\n",
    "source_texts = val_src_txt\n",
    "target_texts = val_trg_tokens\n",
    "bleu=compute_avg_bleu_core(source_tokens, source_texts, target_texts,sample_count, weights)\n",
    "print(\"The Average bleu score on 10 random text on Validation data:%.3f\"%bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Sentence: Je ne suis pas nerveuse.\n",
      "Decoded Sentence: Je ne suis pas sourd.\n",
      "\n",
      "The Average bleu score on 10 random text in Training data:0.304\n",
      "Target Sentence: Je suis seul.\n",
      "Decoded Sentence: Êtes-vous sourd ?\n",
      "\n",
      "The Average bleu score on 10 random text on Validation data:0.144\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "weights = [0.5, 0.5, 0, 0]\n",
    "sample_count = 10 #Number of sentences to consider\n",
    "source_tokens = src_tokens\n",
    "source_texts = train_src_txt\n",
    "target_texts = trg_txts\n",
    "bleu=compute_avg_bleu_core(source_tokens, source_texts, target_texts,sample_count, weights)\n",
    "print(\"The Average bleu score on 10 random text in Training data:%.3f\"%bleu)\n",
    "\n",
    "source_tokens = val_src_tokens\n",
    "source_texts = val_src_txt\n",
    "target_texts = val_trg_tokens\n",
    "bleu=compute_avg_bleu_core(source_tokens, source_texts, target_texts,sample_count, weights)\n",
    "print(\"The Average bleu score on 10 random text on Validation data:%.3f\"%bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Sentence: Je ne suis pas nerveuse.\n",
      "Decoded Sentence: Je ne suis pas sourd.\n",
      "\n",
      "The Average bleu score on 10 random text in Training data:0.186\n",
      "Target Sentence: Je suis seul.\n",
      "Decoded Sentence: Êtes-vous sourd ?\n",
      "\n",
      "The Average bleu score on 10 random text on Validation data:0.069\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "weights = [0.33, 0.33, 0.33, 0]\n",
    "sample_count = 10 #Number of sentences to consider\n",
    "source_tokens = src_tokens\n",
    "source_texts = train_src_txt\n",
    "target_texts = trg_txts\n",
    "bleu=compute_avg_bleu_core(source_tokens, source_texts, target_texts,sample_count, weights)\n",
    "print(\"The Average bleu score on 10 random text in Training data:%.3f\"%bleu)\n",
    "\n",
    "source_tokens = val_src_tokens\n",
    "source_texts = val_src_txt\n",
    "target_texts = val_trg_tokens\n",
    "bleu=compute_avg_bleu_core(source_tokens, source_texts, target_texts,sample_count, weights)\n",
    "print(\"The Average bleu score on 10 random text on Validation data:%.3f\"%bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The 1-gram bleu score is 0.50 for the training data and 0.46 for the test data, 2-gram bleu core is 0.33 for training and 0.27 for testing and 3-gram bleu core is 0.19 for training and 0.07 for testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2S.training_model.save(\"training_model_fr.h5\")\n",
    "S2S.inference_model['encoder'].save(\"enc_inference_fr.h5\")\n",
    "S2S.inference_model['decoder'].save(\"dec_inference_fr.h5\")\n",
    "\n",
    "#Note: Save is giving issue with this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-cv3-dlib-gpu",
   "language": "python",
   "name": "tf-cv3-dlib-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
